### Spark 3 核心优化

##### 1. 自适应查询执行 (Adaptive Query Execution, AQE)

**动态合并 Shuffle 分区：**

1. 分区数过多导致产生小文件，分区数过少导致并行度不足或 OOM
2. 在 Shuffle 结束后，AQE 观察每个分区的大小。如果发现分区太小，会自动将相邻的小分区合并为一个大分区，减少网络 I/O

**动态切换 Join 策略：**

1. 如果 Join 的一侧在过滤/聚合后实际大小小于广播阈值，AQE 会将 **SortMergeJoin**降级为 **BroadcastHashJoin**，从而避免昂贵的 Shuffle

**动态优化倾斜：**

1. 自动检测倾斜的分区（显著大于中位数的分区），并将其**拆分成多个子任务**并行处理，最后再与另一侧的数据进行 Join，解决“长尾效应”。



##### 2. 动态分区裁剪

优化了 星型模型（Star Schema） 下的**大表**（事实表）与**小表**（维度表）的 Join 操作，传统的谓词下推（Predicate Pushdown）只能在读取单一表时生效。DPP 的核心在于：**在运行时，利用 Join 另一侧过滤后的结果来过滤这一侧的数据扫描，**极大减少了磁盘 I/O 和内存占用

**工作流程：**

1. 先对小表（维度表）进行过滤
2. 根据过滤后的结果生成一个谓词（或广播变量）
3. 将此谓词直接应用到大表（事实表）的文件扫描阶段，跳过不相关的分区目录



##### 3. 加速器感知调度

为了让 Spark 更好地支持深度学习和高性能计算，Spark 3.x 引入了对 GPU 等硬件的支持，以前 Spark 只能管理 CPU 和内存，GPU 的使用往往需要**非标准手段**。

**优化点：**

1. 用户可以在 `spark-submit` 中申请 GPU 资源
2. Spark 调度器能感知节点上的 GPU 状态，确保任务被正确分配到有 GPU 的 Executor 上
3. 结合 NVIDIA 的 **RAPIDS** 插件，甚至可以实现 SQL 算子的全 GPU 加速



##### 4. ANSI SQL 兼容性增强

Spark 3.x 致力于更贴近**标准 SQL**（如 PostgreSQL），这对从传统数仓迁移的用户非常重要：

1. **运行时异常**：例如在插入数据溢出或除以零时，Spark 现在可以配置为抛出异常，而不是返回 NULL（符合标准 SQL 行为）
2. **保留字强化**：更严格的语法检查，减少了歧义
3. **内置函数库**：新增了数百个内置函数（如 `transform`, `filter` 等高阶函数在 SQL 中的直接支持）



##### 5. Pandas API 改进与向量化 UDF

针对 Python 开发者，Spark 3.x 通过 **Apache Arrow** 极大提升了数据交换效率：

1. **Pandas UDF 2.0**：利用 Python 类型提示（Type Hints）简化定义
2. **性能提升**：通过**向量化执行**，Python UDF 的性能在某些场景下可提升几十倍，缩小了 **PySpark** 与 Scala/Java 之间的性能差距



##### 6. AQE 开启后，如果我的 Shuffle 分区数设为 2000，最后生成的任务只有 100 个，这是为什么？

1. 这就是 AQE 的“**动态合并分区**”功能
2. Spark 观察到 2000 个分区中大部分数据量很小，为了避免产生过多的 Task 开销和小文件，它将这些分区合并成了 100 个更大的分区。



##### 7. DPP 触发的前提条件是什么？

1. Join 两侧必须有分区列，**想要“裁剪”（跳过不读）的那张大表，必须是按照 Join Key 进行物理分区的**，小表侧必须有一个**过滤条件**，这个过滤条件产生的过滤效果能通过 Join Key 传递给大表
2. 必须是等值连接（Equi-join）
3. 通常在维度表较小、事实表较大的**星型模型**中效果最明显
4. **广播阈值**：通常要求小表侧能够被广播（Broadcast）









